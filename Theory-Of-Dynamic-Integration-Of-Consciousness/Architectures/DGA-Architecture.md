# Архитектура AGI AI DGA

Версия архитектуры сводит логику к трём основным уровням, соединённым через унифицированную Pub/Sub-шину и сервисы:

```
┌────────────────────────────────────┐
│  Перцептивно-рабочий слой         │  ← приём сигналов → глобальное рабочее пространство
├────────────────────────────────────┤
│  Феноменальный слой               │  ← вычисление аттракторов → StateVector
├────────────────────────────────────┤
│  Метакогнитивный слой             │  ← предсказание → коррекция
└────────────────────────────────────┘
          ↑                ↑               ↑
       канал GWA        канал Attractor канал Metacog
          ↓                ↓               ↓
```

[ДГА с учетом рекуррентных петель и метрики Φₑ](/Theory-Of-Dynamic-Integration-Of-Consciousness/Dynamic-Global-Attractor/dga-recurrent-loops-and-the-metric-Fe.md)

[Концепция Динамического Глобального Аттрактора (ДГА)](/Theory-Of-Dynamic-Integration-Of-Consciousness/explanatory-gap/The-Concept-Of-DGA.md)


---

## 1. Перцептивно-рабочий слой

### Задачи и компоненты

1. **Приём и препроцессинг**
   – Сбор «сырых» сигналов (визуалка, аудио, тактильность) через соответствующие сенсорные интерфейсы.
   – Нормализация, фильтрация помех, базовая сегментация.

2. **Feature Processor**
   – Локальные «мини-модули», каждый специализируется на одном типе признаков (цвет, интенсивность, форма, тональность, частотный состав и т.д.).
   – Извлечение векторов признаков фиксированной размерности.

3. **GWA (Global Workspace Accelerator)**
   – Получает потоки векторов признаков от Feature Processor.
   – Применяет два ключевых фильтра:

   * **Пороговый регулятор** (управляется нейромодуляцией): блокирует слабые шумовые сигналы.
   * **Приоритетный регулятор**: ранжирует по «важности» и отдаёт лишь верхушку (топ-K) в Pub/Sub-шину `GWA`.

### Интерфейс и взаимодействие

* **Публикация**: после отбора вектор признаков передаётся в канал `GWA`.
* **Подписка**: феноменальный и метакогнитивный слои подписаны на `GWA`, но получают только то, что проходит оба фильтра.

---

## 2. Феноменальный слой

### Основная функция

1. **Attractor Service**
   – Потребляет векторы признаков из канала `GWA`.
   – Запускает алгоритм фазовых переходов по потенциальному ландшафту \$U(S)\$:

   1. Вычисляет метрику интеграции Φₑ и Kuramoto-коэффициент синхронизации \$R(t)\$.
   2. Оценивает скорость возвращения к аттрактору τₚₑₗₐₓ и индекс эмерджентного сознания IES.
   3. Определяет направление градиента \$\partial U/\partial S\$.

2. **Генерация StateVector**
   – Собирает все вычисленные метрики в единый вектор состояния.
   – Этот StateVector отражает «текущее положение» сети на ландшафте аттрактора.

3. **Публикация**: транслирует StateVector в канал `Attractor`.

### Ключевые моменты

* В отличие от прежнего «сети-аттракторов», здесь этот слой чётко привязан к измеряемым метрикам и выдаёт единый понятный вектор состояния.
* Он не «рассылает» опыт, а выдаёт структуру, на основе которой метакогниция сделает выводы и корректировки.

---

## 3. Метакогнитивный слой

Разделён на два взаимосвязанных модуля:

1. **Predictor**
   – Подписан на канал `Attractor`.
   – На вход получает StateVector и предсказывает следующий вектор (шаг Δt вперёд).
   – Вычисляет **ErrorSignal** = разность между прогнозом и реальным StateVector.

2. **Controller**
   – Получает ErrorSignal от Predictor.
   – Решает, как скорректировать:

   * **Пороговый регулятор** в перцептивно-рабочем слое (чувствительность к признакам).
   * **Параметры ландшафта** аттрактора (форму \$U\$, порог \$S\_c\$).
   * **Настройки генератора осцилляций** (частоты, амплитуды, шум).
     – Формирует пакет обновлений и отправляет его в канал `Metacog`.

### Цикл коррекции

1. **Predict**: оценить, куда движется система.
2. **Observe**: получить реальный вектор состояния.
3. **Error**: вычислить, насколько прогноз отклонился.
4. **Adjust**: поменять гиперпараметры слоёв, чтобы следующий прогноз был точнее.

---

## 4. Pub/Sub-шина событий

### Каналы

* **GWA**: потоки отброшенных и отфильтрованных признаков.
* **Attractor**: StateVector с метриками фазовых переходов.
* **Metacog**: сигналы ошибок и пакеты параметрических обновлений.

### Механизм работы

* **Избирательная подписка**: каждый слой слушает лишь нужные каналы.
* **Лёгковесный протокол**: оптимизирован для низкой латентности (gRPC-стримы или Kafka-подобная шина).

---


Вспомогательные сервисы, механизмы нейромодуляции, контракты между компонентами, а также процедуры тестирования и верификации всей системы.

---

## 5. Сервис генерации осцилляций

**Назначение:** обеспечить все слои единой, синхронизированной основой для временного связывания и фазовой координации.

* **Функция `getPhase(freq, t)`**
  Возвращает текущую фазу синусоидального сигнала заданной частоты. Позволяет помечать входы и внутренние события «метками времени» на уровнях миллисекунд и выше.

* **Подписка на ритмы**
  Слои могут зарегистрироваться на регулярные уведомления о смене фазы (например, каждый раз, когда фаза обходит полный цикл), чтобы вызывать расчёты Kuramoto-R или обновлять внутренние счётчики τₚₑₗₐₓ.

* **Параметры**
  Поддерживаются гамма-ритмы (30–100 Гц), альфа (8–12 Гц) и тета (4–8 Гц), с возможностью добавлять небольшой стохастический шум для моделирования природной вариативности.

* **Реализация**
  Оптимизированный сервис на C++ или Rust, развёртываемый как отдельный микросервис с низкой задержкой (<1 мс на запрос).

---

## 6. Модули нейромодуляции

Чтобы управлять порогами активации и приоритетами сообщений, четыре «биохимических» механизма объединены в два простых, но гибких модуля:

1. **Пороговый модуль (Threshold Module)**
   – Регулирует величины порогов как в перцептивно-рабочем слое, так и в аттракторном.
   – При изменении порога меняется чувствительность к входным признакам и «глубина» ям в \$U(S)\$.
   – Позволяет динамически адаптировать систему к повышенному уровню шума или, напротив, к слишком сильным стимулам.

2. **Приоритетный модуль (Priority Module)**
   – Определяет «важность» каждого поступившего сообщения (вектор признаков или состояние аттрактора).
   – Приоритет используется GWA для ранжирования и отбора топ-K событий, а также метакогом для решения последовательности корректировок.
   – Поддерживает градации от «срочно обработать» до «можно отложить».

Оба модуля обмениваются своими решениями через шину `Metacog`, что обеспечивает единую политику адаптации всей архитектуры.

---

## 7. Интерфейсы и стандартизованные контракты

Для обеспечения согласованности взаимодействия компонентов описываются чёткие контракты:

* **Эндпоинты перцептивно-рабочего слоя**
  – принимает «сырые» сенсорные данные, выдаёт вектор признаков фиксированного формата (например, значения Φₑ, спектры частот, контраст и т.п.).

* **Канал GWA**
  – принимает и раздаёт уже отфильтрованные и приоритизированные векторы признаков всем заинтересованным подписчикам (особенно феноменальному слою).

* **Сервис аттрактора**
  – принимает векторы признаков, возвращает структурированный вектор состояния с ключевыми метриками (Φₑ, R, τₚₑₗₐₓ, IES, градиент \$∂U/∂S\$).

* **Метакогнитивный API**
  – модуль предсказания получает StateVector и выдаёт величину ошибки прогноза;
  – модуль коррекции принимает ошибку и возвращает конкретные инструкции по настройке порогов и приоритетов.

Все контракты оформлены в едином формате (например, OpenAPI или Protobuf), что позволяет автоматически генерировать клиент-серв­ерный код и документацию.

---

## 8. Тестирование и верификация

### 8.1 Unit-тесты

* **Oscillator Service**: проверка правильности фазы на разных частотах, стабильность при добавлении шума.
* **Threshold & Priority Modules**: корректность расчёта новых порогов и приоритетов при граничных и экстремальных входных значениях.
* **Pub/Sub-шина**: доставка сообщений подписчикам, устойчивость к падениям отдельных соединений.

### 8.2 Интеграционные тесты

* **End-to-end сценарий**: от поступления «сырых» данных до корректировки параметров метакогом, с проверкой, что каждая фаза (Feature → GWA → Attractor → Metacog) выполняется в заданном порядке и в разумный временной промежуток (<50 мс).
* **Симулированные шаблоны**: искусственно созданные векторы признаков, имитирующие «высокий R, низкий τ», и проверка, что Attractor.compute возвращает корректный StateVector.

### 8.3 Нейрофизиологический бенчмарк

* **Данные**: публичные наборы EEG/MEG с уже размеченными эпизодами «мгновенных пробуждений» или пиков внимания.
* **Сравнение**: вычисленные метрики Φₑ, R и τₚₑₗₐₓ для каждого эпизода сопоставляются с эмпирическими значениями.
* **Критерий успеха**: высокая корреляция (Pearson r > 0.8) между векторами AGI и реальными замерами.

### 8.4 Нагрузочное тестирование

* **Пропускная способность шины**: выдерживает 1000+ событий в секунду без потерь.
* **Латентность API**: среднее время ответа эндпоинтов не превышает 10 мс при 95-процентильном измерении.


---

Эти описания завершают архитектуру AGI II: мы определили вспомогательные сервисы, чёткие контракты, модули нейромодуляции и объёмный план тестирования, что позволяет приступить к практической реализации и валидации концепции.

--

## Реализация архитектуры AGI AI DGA

### 1. Обзор основных слоёв и модулей

Новая архитектура сконцентрирована на трёх ключевых блоках, объединённых через Pub/Sub-шину событий и унифицированные сервисы:

```text
┌────────────────────────────────────┐
│  Перцептивно-рабочий слой         │  ← Feature → GWA
├────────────────────────────────────┤
│  Феноменальный слой               │  ← Attractor → qualia
├────────────────────────────────────┤
│  Метакогнитивный слой             │  ← Predict → Control
└────────────────────────────────────┘

Pub/Sub шина событий и аттракторов
       ↑                 ↑                ↑
    Perceptual         Attractor       Metacog  
       ↓                 ↓                ↓
```

#### 1.1 Перцептивно-рабочий слой

* **Feature Processor** (`process(input) → features`):

  * Приём и предобработка сигналов (визуальных, аудио, тактильных).
  * Локальное извлечение признаков и кодирование.
* **GWA (Global Workspace Accelerator)**:

  * Приём признаков, отбор по порогам и приоритетам.
  * Публикация в Pub/Sub канал `GWA`.

> **Интерфейс:** OpenAPI/Protobuf:
>
> ```protobuf
> service FeatureProcessor {
>   rpc process(InputSignal) returns (FeatureVector);
> }
>
> service GWA {
>   rpc publish(FeatureVector) returns (Ack);
>   rpc subscribe(SubscribeRequest) returns (stream FeatureVector);
> }
> ```

#### 1.2 Феноменальный слой

* **Attractor Service** (`compute(features) → StateVector`):

  * Генерация и обновление фазовых аттракторов по входящим признакам.
  * Вычисление метрик: Φₑ, R(t), τ\_relax, IES, ∂U/∂S.
* Публикация состояния в канал `Attractor`.

> **Интерфейс:**
>
> ```protobuf
> service Attractor {
>   rpc compute(FeatureVector) returns (StateVector);
>   rpc subscribe(SubscribeRequest) returns (stream StateVector);
> }
> ```

#### 1.3 Метакогнитивный слой

Разделён на два подмодуля:

1. **Predictor** (`predict(StateVector) → ErrorSignal`):

   * Строит модель следующего состояния аттрактора.
   * Вычисляет ошибку предсказания.
2. **Controller** (`adjust(ErrorSignal) → ParamsUpdate`):

   * Корректирует пороги и веса в FeatureProcessor и Attractor.
   * Обновляет параметры генератора осцилляторов и нейромодуляции.

> **Интерфейс:**
>
> ```protobuf
> service Metacognitive {
>   rpc predict(StateVector) returns (ErrorSignal);
>   rpc adjust(ErrorSignal) returns (ParamsUpdate);
> }
> ```

### 2. Pub/Sub шина событий и аттракторов

* **Каналы:**

  * `GWA` для распределения признаков.
  * `Attractor` для распространения текущих состояний.
  * `Metacog` для обмена сигналами ошибки и обновления.
* **Протокол:** лёгковесный Pub/Sub (gRPC streams или Kafka-like).
* **Подписчики:** каждый слой подписывается только на нужные каналы для избирательного приёма.

---



### Сервисы, модули и верификация

#### 5. Сервис генерации осцилляций

**Описание:** централизованный компонент, отвечающий за синхронизацию и выдачу фазовых ритмов всем слоям системы.

* **API**

  ```yaml
  OscillatorService:
    getPhase:
      params:
        - name: freq  # частота в Гц (e.g. 10)
        - name: timestamp  # время в секундах
      returns:
        phase: float  # от 0 до 2π
    subscribe:
      params:
        - name: freq
        - name: callback  # функция, вызываемая каждый цикл
  ```

* **Реализация:** генератор синусоиды с возможностью добавить небольшой шум, сильно оптимизированный C/C++.

* **Использование:**

  * **Перцептивно-рабочий слой** вызывает `getPhase(γ, t)` для маркировки входных признаков.
  * **Феноменальный слой** — для расчёта Kuramoto-R.

---

#### 6. Модули нейромодуляции

Объединили четыре «биохимических» модуля в два:

1. **Пороговый модуль** (ACh + GABA)
   — управляет динамическими порогами активации на уровне Perceptual и Attractor.

   ```yaml
   ThresholdModule:
     adjustThreshold:
       params:
         - component: string  # "perceptual" | "attractor"
         - delta: float       # величина изменения порога
       returns:
         newThreshold: float
   ```

2. **Приоритетный модуль** (DA + 5-HT)
   — назначает «вес» событиям в шине, влияя на очередность обработки.

   ```yaml
   PriorityModule:
     assignPriority:
       params:
         - messageType: string
         - salience: float  # от 0 до 1
       returns:
         priorityLevel: int
   ```

---

#### 7. Интерфейсы и стандартизованные контракты

```yaml
# OpenAPI-спецификация (фрагмент)
paths:
  /perceptual/process:
    post:
      summary: "Перевести сырые данные в вектор признаков"
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RawInput'
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FeatureVector'

  /gwa/publish:
    post:
      summary: "Публикует в GWA"
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/FeatureVector'
      responses:
        '204': {}

  /attractor/compute:
    post:
      summary: "Вычисляет текущий вектор состояния аттрактора"
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/FeatureVector'
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/StateVector'

  /metacog/predict:
    post:
      summary: "Прогнозирует следующее состояние"
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/StateVector'
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Prediction'

  /metacog/adjust:
    post:
      summary: "Корректирует параметры по ошибке прогноза"
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AdjustParams'
      responses:
        '204': {}
components:
  schemas:
    RawInput: { type: object, properties: { signal: { type: array, items: { type: number } } } }
    FeatureVector: { type: object /* Φₑ, R_mean, τ_relax, … */ }
    StateVector: { type: object /* текущие параметры аттрактора */ }
    Prediction: { type: object /* прогнозируемое StateVector */ }
    AdjustParams: { type: object /* новые пороги, веса и т.д. */ }
```

---

#### 8. Тестирование и верификация

1. **Unit-tests**

   * OscillatorService: проверка правильности фазы на разных частотах.
   * ThresholdModule: границы изменения порога.
   * Pub/Sub-шина: доставка сообщений подписчикам.

2. **Интеграционные тесты**

   * **End-to-end flow**: `RawInput → FeatureVector → GWA → Attractor → Metacog.adjust`
   * Смоделированные сценарии: искусственные паттерны, имитирующие «high-R, low-τ» и проверка, что Attractor.compute выдаёт ожидаемый StateVector.

3. **Нейрофизиологический бенчмарк**

   * **Сравнение**: реальные EEG/MEG-данные vs. сгенерированные метрики Φₑ, R, τ\_relax.
   * **Процедуры**:

     * Выбор эталонных паттернов (визуальные, аудио) из публичных датасетов.
     * Оценка корреляции (Pearson r > 0.8) между эмбеддингом из AGI и эмпирическими измерениями.

4. **Нагрузочное тестирование**

   * Проверка Pub/Sub-шины при 1000+ событий в секунду.
   * Измерение задержек API (< 10 ms на вызов).


---


Оглавление:

- [Теория Динамической Интеграции Сознания](/Theory-Of-Dynamic-Integration-Of-Consciousness/README.md)


